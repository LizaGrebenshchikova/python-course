{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(data_path):\n",
    "\n",
    "    file_data = open(data_path)\n",
    "\n",
    "    data = []\n",
    "    for string in file_data:\n",
    "        comma = string.find(',')\n",
    "        subject = comma + string[comma:].find(':') + 2\n",
    "        sn = -1\n",
    "        data.append([string[:comma], string[subject:sn]])\n",
    "\n",
    "    #print(data[:4])\n",
    "\n",
    "    file_data.close()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_X_and_Y_Train(data_path):\n",
    "    \n",
    "    data = get_data_from_file(data_path)[1:]\n",
    "    X_Train = [x[1] for x in data]\n",
    "    Y_Train = [y[0] for y in data]\n",
    "    \n",
    "    return X_Train, Y_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re : 2 . 882 s - > np np > date : sun , 15 dec 91 02 : 25 : 02 est > from : michael < mmorse @ vm1 . yorku . ca > > subject : re : 2 . 864 queries > > wlodek zadrozny asks if there is \"\" anything interesting \"\" to be said > about the construction \"\" s > np np \"\" . . . second , > and very much related : might we consider the construction to be a form > of what has been discussed on this list of late as reduplication ? the > logical sense of \"\" john mcnamara the name \"\" is tautologous and thus , at > that level , indistinguishable from \"\" well , well now , what have we here ? \"\" . to say that ' john mcnamara the name ' is tautologous is to give support to those who say that a logic-based semantics is irrelevant to natural language . in what sense is it tautologous ? it supplies the value of an attribute followed by the attribute of which it is the value . if in fact the value of the name-attribute for the relevant entity were ' chaim shmendrik ' , ' john mcnamara the name ' would be false . no tautology , this . ( and no reduplication , either . )\"\n"
     ]
    }
   ],
   "source": [
    "X_Train, Y_Train = get_X_and_Y_Train(data_path)\n",
    "\n",
    "print(X_Train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_PRINT = True\n",
    "\n",
    "def mprint(*arg):\n",
    "    if GLOBAL_PRINT:\n",
    "        print(*arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        self.category_priors = category_priors\n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "\n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = Counter()\n",
    "\n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = Counter()\n",
    "        \n",
    "        # Все категории сообщений\n",
    "        self.categories = defaultdict()\n",
    "        \n",
    "        # Количество всех слов во всех сообщениях (считая, что в каждом сообщении все слова - уникальные)\n",
    "        self.total = 0\n",
    "        \n",
    "        # Обучен ли классификатор\n",
    "        self.isFit = False\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        \n",
    "        ts = time.time()\n",
    "        \n",
    "        if x_train.__class__ == str:\n",
    "            x_train = [x_train]\n",
    "        \n",
    "        for y in y_train:\n",
    "            self.category_doc_counts[y] += 1\n",
    "            \n",
    "        self.categories = self.category_doc_counts.keys()\n",
    "        \n",
    "        for x_ind in range(len(x_train)):\n",
    "            if x_train[x_ind].__class__ == str:\n",
    "                msg = x_train[x_ind].split(' ')\n",
    "            else:\n",
    "                msg = x_train[x_ind]\n",
    "            \n",
    "            for word_ind in range(len(msg)):\n",
    "                if msg.count(msg[word_ind]) > 1 and msg.index(msg[word_ind]) != word_ind:\n",
    "                    continue\n",
    "                    \n",
    "                self.feature_counts[msg[word_ind].lower()] += 1\n",
    "                \n",
    "                self.feature_category_counts[msg[word_ind].lower()][y_train[x_ind]] += 1\n",
    "        \n",
    "        self.total = 0\n",
    "        for w in self.feature_counts:\n",
    "            self.total += self.feature_counts[w]\n",
    "        \n",
    "        # Если априорные вероятности категорий не заданы, то надо аппроксимировать их\n",
    "        if self.category_priors is None:\n",
    "            self.category_priors = defaultdict()\n",
    "            s = 0 #можно ли это написать с помощью sum(self.category_doc_counts.values())?\n",
    "            for x in self.category_doc_counts.values():\n",
    "                s += x\n",
    "            for cat in self.categories:\n",
    "                self.category_priors[cat] = self.category_doc_counts[cat] / s\n",
    "\n",
    "        tf = time.time()\n",
    "        mprint('Fit time:', (tf-ts) // 60, 'minutes and ', (tf-ts) % 60, 'seconds')\n",
    "        \n",
    "        self.isFit = True\n",
    "        return self\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.isFit:\n",
    "            return\n",
    "        \n",
    "        if text.__class__ == str:\n",
    "            text = [text]\n",
    "            \n",
    "        categories = []\n",
    "        for t_ind in range(len(text)):\n",
    "            if text[t_ind].__class__ == str:\n",
    "                msg = text[t_ind].split(' ')\n",
    "            else:\n",
    "                msg = text[t_ind]\n",
    "            \n",
    "            p_categories = self.get_probs(msg)\n",
    "                \n",
    "            cat_answer = None\n",
    "            for cat in p_categories:\n",
    "                if cat_answer is None:\n",
    "                    cat_answer = cat\n",
    "                    break\n",
    "                if p_categories[cat] > p_categories[cat_answer]:\n",
    "                    cat_answer = cat    \n",
    "\n",
    "            categories.append(cat_answer)\n",
    "            \n",
    "        return categories\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        \"\"\"\n",
    "        Возвращает точность предсказаний на text для правильных категорий labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "        labels : list of str\n",
    "            Список категорий для каждого токена из text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : float\n",
    "            Точность предсказания.\n",
    "        \"\"\"\n",
    "        if not self.isFit:\n",
    "            return\n",
    "        \n",
    "        return accuracy_score(self.predict(text), labels)\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которую будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.isFit:\n",
    "            return\n",
    "        \n",
    "        # Токенизируем текст, если это необходимо\n",
    "        \n",
    "        if text.__class__ == str:\n",
    "            msg = text.split(' ')\n",
    "        else:\n",
    "            msg = text\n",
    "        \n",
    "        def mpow(n, base=len(self.categories)):\n",
    "            if n > 20:\n",
    "                return inf\n",
    "            return base**n\n",
    "        \n",
    "        p_categories = defaultdict(lambda: float())\n",
    "        for cat in self.categories:\n",
    "            p_categories[cat] = mpow(self.get_category_prob(cat, msg))\n",
    "        \n",
    "        return p_categories\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятность принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.isFit:\n",
    "            return\n",
    "                \n",
    "        def mlog(n, base=len(self.categories)):\n",
    "            if n == 0:\n",
    "                return 0\n",
    "            return math.log(n, base)\n",
    "        \n",
    "        p_cat = mlog(self.category_priors[cat])\n",
    "        for word in text:\n",
    "            p_cat += mlog(self.get_weighted_feature_prob(cat, word))\n",
    "        \n",
    "        return p_cat\n",
    "\n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        \"\"\"\n",
    "        Вычисляет взвешенную вероятность P(Слово|Категория).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        feature : str\n",
    "            Слово из текста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Возвращает взвешенную вероятность слова feature при условии категории cat.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.isFit:\n",
    "            return\n",
    "        \n",
    "        p_w_i_s = self.feature_category_counts[feature][cat] / self.category_doc_counts[cat]\n",
    "        p_cat = 1 / len(self.categories)\n",
    "        a = self.weight * p_cat + self.total * p_w_i_s\n",
    "        b = self.weight + self.total\n",
    "        return a / b\n",
    "\n",
    "    def get_categories(self):\n",
    "        \"\"\"\n",
    "        Возвращает список названий всех категорий.\n",
    "        Returns\n",
    "        -------\n",
    "        cat_list : list of str\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.isFit:\n",
    "            return\n",
    "        \n",
    "        return self.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham: 0\n",
      "spam: 0\n",
      "dict_keys([])\n",
      "get 0\n",
      "percent None\n",
      "percent None\n",
      "defaultdict(<class 'int'>, {})\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "\n",
    "#nb.fit(X_Train, Y_Train)\n",
    "\n",
    "mprint('ham:', nb.category_doc_counts['ham'])\n",
    "mprint('spam:', nb.category_doc_counts['spam'])\n",
    "\n",
    "mprint(nb.category_doc_counts.keys())\n",
    "mprint('get', nb.feature_counts['get'])\n",
    "\n",
    "mprint('percent', nb.get_category_prob('ham', X_Train[243]))\n",
    "mprint('percent', nb.get_category_prob('spam', X_Train[243]))\n",
    "\n",
    "mprint(nb.feature_category_counts['get'])\n",
    "\n",
    "mprint(nb.category_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1.0 minutes and  50.2456419467926 seconds\n",
      "0.837931034483\n",
      "Fit time: 1.0 minutes and  41.33989977836609 seconds\n",
      "0.848275862069\n",
      "Fit time: 1.0 minutes and  43.44826698303223 seconds\n",
      "0.831034482759\n",
      "Fit time: 1.0 minutes and  49.10855579376221 seconds\n",
      "0.83044982699\n",
      "Fit time: 1.0 minutes and  46.38993811607361 seconds\n",
      "0.826989619377\n",
      "Fit time: 3.0 minutes and  34.54800796508789 seconds\n",
      "0.851211072664\n",
      "Fit time: 1.0 minutes and  26.241960048675537 seconds\n",
      "0.83044982699\n",
      "Fit time: 1.0 minutes and  30.21858310699463 seconds\n",
      "0.795847750865\n",
      "Fit time: 1.0 minutes and  24.656397104263306 seconds\n",
      "0.861591695502\n",
      "Fit time: 2.0 minutes and  8.112924098968506 seconds\n",
      "0.823529411765\n"
     ]
    }
   ],
   "source": [
    "def test_myNB():\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    X = np.array(X_Train)\n",
    "    Y = np.array(Y_Train)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        nb = NaiveBayes()\n",
    "        nb.fit(X_train, y_train)\n",
    "        print(nb.score(X_test, y_test))\n",
    "        \n",
    "test_myNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения классификатора не достигают заявленных в условии 90%, однако после сравнения с результатом nltk я принял решение не улучшать его. (См. комментарий под запуском nltk.)\n",
    "\n",
    "P.S. На некоторых запусках результат был стабильно 85-87%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных для классификатора nltk, если требуется\n",
    "from nltk.tokenize import word_tokenize\n",
    "from itertools import chain\n",
    "\n",
    "def get_data_for_nltk(X, y):\n",
    "    \n",
    "    training_data = [*zip(X, y)]\n",
    "    \n",
    "    vocabulary = set(chain(*[word_tokenize(i[0].lower()) for i in training_data]))\n",
    "\n",
    "    feature_set = [({i:(i in word_tokenize(sentence.lower())) for i in vocabulary}, tag) for sentence, tag in training_data[:2]]\n",
    "    \n",
    "    #print(feature_set)\n",
    "    return feature_set, vocabulary\n",
    "\n",
    "def get_data_for_test(test_sentence, vocabulary):\n",
    "    test_sentence = \"This is the best band I've ever heard!\"\n",
    "    featurized_test_sentence =  {i:(i in word_tokenize(test_sentence.lower())) for i in vocabulary}\n",
    "\n",
    "    return featurized_test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train\n",
      "Finish train\n",
      "NBC Fit time: 1.0 minutes and  50.3898708820343 seconds\n",
      "Score: 0.833333333333\n",
      "NBC Classify time: 18.0 minutes and  27.780794143676758 seconds\n",
      "CPU times: user 19min 42s, sys: 9.96 s, total: 19min 52s\n",
      "Wall time: 20min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "kfc = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "X = np.array(X_Train[:1500]) #ибо уж очень долго работало\n",
    "Y = np.array(Y_Train[:1500])\n",
    "\n",
    "for train_index, test_index in kfc.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "    ts = time.time()\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    print('Start train')\n",
    "    \n",
    "    data, vocabulary = get_data_for_nltk(X_train, y_train)\n",
    "    nbc = NaiveBayesClassifier.train(data)\n",
    "    \n",
    "    print('Finish train')\n",
    "    \n",
    "    tf = time.time()\n",
    "    mprint('NBC Fit time:', (tf-ts) // 60, 'minutes and ', (tf-ts) % 60, 'seconds')\n",
    "    \n",
    "    ts = time.time()\n",
    "    \n",
    "    cats = []\n",
    "    for test in X_test:\n",
    "        cats.append(nbc.classify(get_data_for_test(test, vocabulary)))\n",
    "        \n",
    "    print('Score:', accuracy_score(cats, y_test))\n",
    "    \n",
    "    tf = time.time()\n",
    "    mprint('NBC Classify time:', (tf-ts) // 60, 'minutes and ', (tf-ts) % 60, 'seconds')\n",
    "    \n",
    "    break\n",
    "    \n",
    "    #print(nbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь всего одна итерация, так как на неё было затрачено порядка 22 минут (то есть на весь цикл уйдёт порядка 4 часов), а результат классификатора nltk несильно отличается от того, что написан мной.\n",
    "\n",
    "Пример на случай запуска кода:\n",
    "\n",
    "![png](https://gyazo.com/608c2e8fa881b6b9259289113f365c8f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пока я не понял, как получить эти графики из исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
